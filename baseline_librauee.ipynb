{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "作者：librauee\n",
    "微信公众号：老肥码码码\n",
    "日期：2020.12.10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 29.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# 目标编码\n",
    "def kfold_mean(df_train, df_test, target, target_mean_list):\n",
    "    folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    mean_of_target = df_train[target].mean()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in tqdm(\n",
    "            enumerate(folds.split(df_train, y=df_train['label']))):\n",
    "        tr_x = df_train.iloc[trn_idx, :]\n",
    "        vl_x = df_train.iloc[val_idx, :]\n",
    "\n",
    "        for col in target_mean_list:\n",
    "            df_train.loc[vl_x.index, f'{col}_target_enc'] = vl_x[col].map(\n",
    "                tr_x.groupby(col)[target].mean())\n",
    "\n",
    "    for col in target_mean_list:\n",
    "        df_train[f'{col}_target_enc'].fillna(mean_of_target, inplace=True)\n",
    "\n",
    "        df_test[f'{col}_target_enc'] = df_test[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "\n",
    "        df_test[f'{col}_target_enc'].fillna(mean_of_target, inplace=True)\n",
    "    return pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "feature_list =  ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT'\n",
    "                   ]\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "data = kfold_mean(data[~data['label'].isna()], data[data['label'].isna()],\n",
    "                  'label',\n",
    "                  feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 频数统计\n",
    "cat_col = ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "for col in cat_col:\n",
    "    data[col + '_COUNT'] = data[col].map(data[col].value_counts())\n",
    "    col_idx = data[col].value_counts()\n",
    "    for idx in col_idx[col_idx < 10].index:\n",
    "        data[col] = data[col].replace(idx, -1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偏离值特征\n",
    "group_list = ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "num_feature_list = ['GRYJCE', 'DKFFE', 'DKLL', 'DKYE', 'GRJCJS', 'GRZHSNJZYE', 'GRZHDNGJYE']                   \n",
    "for group in group_list:\n",
    "    for feature in num_feature_list:\n",
    "        tmp = data.groupby(group)[feature].agg([sum, min, max, np.mean]).reset_index()\n",
    "        tmp = pd.merge(data, tmp, on=group, how='left')\n",
    "        data['{}-mean_gb_{}'.format(feature, group)] = data[feature] - tmp['mean']\n",
    "        data['{}-min_gb_{}'.format(feature, group)] = data[feature] - tmp['min']\n",
    "        data['{}-max_gb_{}'.format(feature, group)] = data[feature] - tmp['max']\n",
    "        data['{}/sum_gb_{}'.format(feature, group)] = data[feature] / tmp['sum']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = data[~data['label'].isna()], data[data['label'].isna()]\n",
    "y = X_train['label']\n",
    "drop_features = ['label', 'id', 'CSNY']\n",
    "\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_test = X_test.drop(drop_features, axis=1)\n",
    "\n",
    "cat_col = ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "X_train[cat_col] = X_train[cat_col].astype('category')\n",
    "X_test[cat_col] = X_test[cat_col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [ 7984  7985  7986 ... 39997 39998 39999]\n",
      "val_idx: [   0    1    2 ... 8249 8282 8288]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's auc: 0.997291\tvalid_1's auc: 0.940104\n",
      "fold n°1\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [ 7984  7985  7986 ... 15997 15998 15999]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.983148\tvalid_1's auc: 0.933742\n",
      "fold n°2\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [16000 16001 16002 ... 24382 24393 24455]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's auc: 0.996285\tvalid_1's auc: 0.918845\n",
      "fold n°3\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [23964 23965 23966 ... 32011 32014 32019]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.920535\n",
      "Early stopping, best iteration is:\n",
      "[357]\ttraining's auc: 0.999989\tvalid_1's auc: 0.921398\n",
      "fold n°4\n",
      "trn_idx: [    0     1     2 ... 32011 32014 32019]\n",
      "val_idx: [31996 31997 31998 ... 39997 39998 39999]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's auc: 0.999635\tvalid_1's auc: 0.924317\n",
      "AUC score: 0.9239004594037974\n",
      "TPR weight: 0.46521581429089587\n"
     ]
    }
   ],
   "source": [
    "# 训练&预测\n",
    "KF = StratifiedKFold(n_splits=5, random_state=2020)\n",
    "params = {\n",
    "    'verbose':-1, \n",
    "    'objective':'binary',\n",
    "    'metric':'auc',\n",
    "    'num_iterations': 10000, \n",
    "}\n",
    "\n",
    "\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros((len(X_test)))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:',trn_idx)\n",
    "    print('val_idx:',val_idx)\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx],label=y.iloc[trn_idx])    \n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx],label=y.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=200,  \n",
    "        categorical_feature=cat_col\n",
    "    )\n",
    "        \n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    predictions_lgb[:] += clf.predict(X_test, num_iteration=clf.best_iteration) \n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_lgb)))\n",
    "print(\"TPR weight: {}\".format(tpr_weight_funtion(y, oof_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/submit.csv')\n",
    "submit['label'] = predictions_lgb / 5\n",
    "submit.to_csv('submit_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
